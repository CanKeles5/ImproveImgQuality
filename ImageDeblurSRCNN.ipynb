{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ImageDeblurSRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeO0R6ZfFCGGFmp60bLl5e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CanKeles5/ImproveImgQuality/blob/main/ImageDeblurSRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZenVDBxP-eN"
      },
      "source": [
        "%reload_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV4OEIY6QIMw"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch.utils.data.sampler\r\n",
        "import torchvision.transforms.functional as TF\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from PIL import Image, ImageFilter\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import numpy\r\n",
        "import random\r\n",
        "import fnmatch\r\n",
        "import numpy as np\r\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs6z5NiTQIJj",
        "outputId": "a37dbc29-2ac9-4bd0-d3be-57bf18591f60"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tfRE2a6QIHH"
      },
      "source": [
        "! mkdir -p ~/.kaggle/\r\n",
        "! mv kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvsIMrLwQIEk",
        "outputId": "a8f2b1e7-01a7-4573-e6e8-28ea03dbcfbb"
      },
      "source": [
        "! kaggle datasets download -d jessicali9530/celeba-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading celeba-dataset.zip to /content\n",
            " 99% 1.32G/1.33G [00:08<00:00, 128MB/s]\n",
            "100% 1.33G/1.33G [00:08<00:00, 175MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGm2PMq2QH_K"
      },
      "source": [
        "path = \"/content/celeba-dataset.zip\"\r\n",
        "to = \"/content/dataset\"\r\n",
        "! unzip -q -n {path} -d {to}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez538EF0QVV4",
        "outputId": "a971fe2d-616f-4736-d2d7-aca538249e05"
      },
      "source": [
        "im_path = \"/content/dataset/img_align_celeba.zip\"\r\n",
        "imgs = \"/content/images\"\r\n",
        "! unzip -q -n {im_path} -d {imgs}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/dataset/img_align_celeba.zip, /content/dataset/img_align_celeba.zip.zip or /content/dataset/img_align_celeba.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULQmhVUIQVTa"
      },
      "source": [
        "folder = \"/content/dataset/img_align_celeba/img_align_celeba\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVwv2ugBQVRU"
      },
      "source": [
        "image_paths = []\r\n",
        "\r\n",
        "for (path, dirnames, filenames) in os.walk(folder):\r\n",
        "  image_paths.extend(os.path.join(path, name) for name in filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPQJukDQVOg"
      },
      "source": [
        "class MyDataset(Dataset):\r\n",
        "  def __init__(self, image_paths, train=True):\r\n",
        "    self.image_paths = image_paths\r\n",
        "    \r\n",
        "  def transform(self, image):\r\n",
        "    resize = transforms.Resize(size=(128, 128))\r\n",
        "    #image = resize(image)\r\n",
        "    image = TF.to_tensor(image)\r\n",
        "    \r\n",
        "    return image\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    #image = Image.open(self.image_paths[index]) #open the image as PIL image\r\n",
        "    orig_image = cv2.imread(self.image_paths[index], cv2.IMREAD_COLOR)\r\n",
        "    orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\r\n",
        "\r\n",
        "    orig_image = orig_image[0:217, 0:177]\r\n",
        "\r\n",
        "    #height, width = orig_image.shape[:2]\r\n",
        "    #print(height, width)\r\n",
        "\r\n",
        "    augmented_image = cv2.GaussianBlur(orig_image, (21, 21), 0)\r\n",
        "    x = self.transform(orig_image)\r\n",
        "    y = self.transform(augmented_image)\r\n",
        "\r\n",
        "    #print(\"x.shape: \", x.shape)\r\n",
        "    #print(\"y.shape: \", y.shape)\r\n",
        "\r\n",
        "    return x, y\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gXnWb5iQVME",
        "outputId": "7004373d-b265-4113-a679-e728b3194a7e"
      },
      "source": [
        "print(len(image_paths))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s4lLQ0pQVJe"
      },
      "source": [
        "train_paths = image_paths[0:10000]\r\n",
        "valid_paths = image_paths[10001:12001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQpxXUNYQVGv"
      },
      "source": [
        "train_set = MyDataset(train_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6SYI-WQU91"
      },
      "source": [
        "valid_set = MyDataset(valid_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnAaNu7KQU6p"
      },
      "source": [
        "bs=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4cgIJDyQUjR"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=bs)\r\n",
        "valid_loader = DataLoader(valid_set, batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6v4e3ncRZyU"
      },
      "source": [
        "class DeblurCNN(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(DeblurCNN, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=2)\r\n",
        "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=2)\r\n",
        "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = F.relu(self.conv2(x))\r\n",
        "        x = self.conv3(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmqjssBx7fW"
      },
      "source": [
        "class SRCNN(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(SRCNN, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=2, padding_mode='replicate') # padding mode same as original Caffe code\r\n",
        "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=2, padding_mode='replicate')\r\n",
        "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2, padding_mode='replicate')\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = F.relu(self.conv2(x))\r\n",
        "        x = self.conv3(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWr0EShCQl4j"
      },
      "source": [
        "class D(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(D, self).__init__()\r\n",
        "    self.main = nn.Sequential(        \r\n",
        "        nn.Conv2d(3, 16, 4, 4, 0),\r\n",
        "        nn.LeakyReLU(0.2),\r\n",
        "        \r\n",
        "        nn.Conv2d(16, 32, 4, 4, 0),\r\n",
        "        nn.BatchNorm2d(32),\r\n",
        "        nn.LeakyReLU(0.2),\r\n",
        "        \r\n",
        "        nn.Conv2d(32, 32, 4, 4, 0),\r\n",
        "        nn.BatchNorm2d(32),\r\n",
        "        nn.LeakyReLU(0.2),\r\n",
        "\r\n",
        "        nn.Conv2d(32, 1, 2, 2, 0),\r\n",
        "        nn.Sigmoid()\r\n",
        "    )\r\n",
        "    \r\n",
        "  def forward(self, im):\r\n",
        "    return self.main(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-KFf8psQl1v"
      },
      "source": [
        "#Generator = G().to(device)\r\n",
        "Generator = SRCNN().to(device)\r\n",
        "Discriminator = D().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HC6zbB5Qlze"
      },
      "source": [
        "def weights_init(m):\r\n",
        "    if isinstance(m, nn.Conv2d):\r\n",
        "        m.weight.data.normal_(0, 0.02)\r\n",
        "        m.bias.data.normal_(0, 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eim2CatOQlwz"
      },
      "source": [
        "weights_init(Generator)\r\n",
        "weights_init(Discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJPSJtZDQuKb",
        "outputId": "8e00210c-c388-4de6-a551-05ff7f44f9c5"
      },
      "source": [
        "print(\"Number of parameters in Generator: \", sum([p.numel() for p in Generator.parameters()]))\r\n",
        "print(\"Number of parameters in Discriminator: \", sum([p.numel() for p in Discriminator.parameters()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in Generator:  20099\n",
            "Number of parameters in Discriminator:  25681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaDRMeJYQuHF"
      },
      "source": [
        "criterion = nn.BCELoss()\r\n",
        "adv_criterion = nn.BCELoss()\r\n",
        "l1_criterion = nn.MSELoss()\r\n",
        "G_optim = torch.optim.Adam(Generator.parameters(), lr=1e-4)\r\n",
        "D_optim = torch.optim.Adam(Discriminator.parameters(), lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYavFEwYQuDl",
        "outputId": "c4b864e0-9580-4a71-f189-9ef2a7a78e43"
      },
      "source": [
        "Discriminator.train()\r\n",
        "Generator.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SRCNN(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n",
              "  (conv2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n",
              "  (conv3): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErWpAimIQuAD"
      },
      "source": [
        "def save_pic(epoch_no, im):\r\n",
        "  Generator.eval()\r\n",
        "  \r\n",
        "  im = im.unsqueeze(0).to(device)\r\n",
        "\r\n",
        "  output = Generator(im)\r\n",
        "  \r\n",
        "  output = output[0].detach().cpu()\r\n",
        "  output = (output+1)/2\r\n",
        "  output = output.clamp(0.0, 1.0)\r\n",
        "\r\n",
        "  PIL_img = transforms.ToPILImage()(output)\r\n",
        "  PIL_img = PIL_img.save(str(epoch_no) + \".jpg\")\r\n",
        "  Generator.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkEQLDNfQt80"
      },
      "source": [
        "D_losses_train = []\r\n",
        "G_losses_train = []\r\n",
        "\r\n",
        "D_losses_valid = []\r\n",
        "G_losses_valid = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MNpiaIJQt5t"
      },
      "source": [
        "def shuffle_data(fake_im, real_im):\r\n",
        "  batch_size=fake_im.shape[0]\r\n",
        "\r\n",
        "  data=torch.cat((fake_im, real_im),dim=0)\r\n",
        "  labels=torch.cat((torch.zeros(batch_size), torch.ones(batch_size)))\r\n",
        "  \r\n",
        "  return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHdgCg70Qt0V",
        "outputId": "8ead2787-b7ae-433c-e9c6-784c3bf1106f"
      },
      "source": [
        "n_epochs = 50\r\n",
        "\r\n",
        "adv_coeff = 0.00\r\n",
        "\r\n",
        "for epoch in range(n_epochs):\r\n",
        "  D_train_loss = 0.0\r\n",
        "  G_train_loss = 0.0\r\n",
        "\r\n",
        "  D_valid_loss = 0.0\r\n",
        "  G_valid_loss = 0.0\r\n",
        "\r\n",
        "  Generator.train()\r\n",
        "  Discriminator.train()\r\n",
        "\r\n",
        "  for i, (real_im, augmented_im) in enumerate(train_loader):\r\n",
        "    (transforms.ToPILImage()(real_im[0])).save(\"real_im\" + str(epoch) + \".jpg\")\r\n",
        "    (transforms.ToPILImage()(augmented_im[0])).save(\"augmented_im\" + str(epoch) + \".jpg\")\r\n",
        "    real_im = (real_im*2.0)-1\r\n",
        "\r\n",
        "    #augmented_im = augment_image(real_im, i, bs)\r\n",
        "\r\n",
        "    augmented_im = augmented_im.to(device)\r\n",
        "    real_im = real_im.type(torch.FloatTensor)\r\n",
        "    real_im=real_im.to(device)\r\n",
        "    \r\n",
        "    if i==0:\r\n",
        "      save_pic(epoch, augmented_im[0])\r\n",
        "    \r\n",
        "    ##########MSE loss update############\r\n",
        "    G_optim.zero_grad()\r\n",
        "    fake_img = Generator(augmented_im)\r\n",
        "\r\n",
        "    G_loss_l1 = l1_criterion(fake_img, real_im)\r\n",
        "    G_train_loss += G_loss_l1.item() #for plotting loss\r\n",
        "    G_loss_l1.backward(retain_graph=True)\r\n",
        "    G_optim.step()\r\n",
        "    \r\n",
        "    ####################################\r\n",
        "    \r\n",
        " \r\n",
        "    \r\n",
        "    ###########################################\r\n",
        "  \r\n",
        "  Generator.eval()\r\n",
        "  Discriminator.eval()\r\n",
        "  \r\n",
        "  with torch.no_grad():\r\n",
        "    for i, (real_im, augmented_im) in enumerate(valid_loader):\r\n",
        "      if(real_im.shape[0]!=bs):\r\n",
        "        break\r\n",
        "\r\n",
        "      real_im = 2*real_im-1\r\n",
        "\r\n",
        "      #augmented_img = augment_image(real_im, i, bs)\r\n",
        "      augmented_im = augmented_im.to(device)\r\n",
        "      real_im=real_im.to(device)\r\n",
        "\r\n",
        "      fake_img = Generator(augmented_im)\r\n",
        "\r\n",
        "      if i==0:\r\n",
        "        save_pic(epoch, augmented_im[0])\r\n",
        "\r\n",
        "      #guess = Discriminator(fake_img).squeeze(1).squeeze(1).squeeze(1)\r\n",
        "\r\n",
        "      #adv_loss = adv_criterion(guess, torch.ones(bs).to(device))\r\n",
        "      l1_loss = l1_criterion(fake_img, real_im)\r\n",
        "      G_loss = l1_loss #+ adv_loss*adv_coeff\r\n",
        "      G_valid_loss += G_loss.item()\r\n",
        "  \r\n",
        "  G_train_loss = G_train_loss/len(train_set)\r\n",
        "  G_valid_loss = G_valid_loss/len(valid_set)\r\n",
        "  G_losses_train.append(G_train_loss)\r\n",
        "  G_losses_valid.append(G_valid_loss)\r\n",
        "  \r\n",
        "  print(\"Epoch \" + str(epoch) + \", Train: \" + str(G_train_loss) + \" , Validation: \" + str(G_valid_loss))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Train: 0.005778708363836631 , Validation: 0.0031184972245246172\n",
            "Epoch 1, Train: 0.0031129934805445374 , Validation: 0.0029390273531898856\n",
            "Epoch 2, Train: 0.002870716022932902 , Validation: 0.002661334774689749\n",
            "Epoch 3, Train: 0.002540718667767942 , Validation: 0.0022475087116472425\n",
            "Epoch 4, Train: 0.002179428832093254 , Validation: 0.0020443432530155405\n",
            "Epoch 5, Train: 0.0020606144890422 , Validation: 0.0019708525063470007\n",
            "Epoch 6, Train: 0.002008146549714729 , Validation: 0.0019351340647554025\n",
            "Epoch 7, Train: 0.001975712436181493 , Validation: 0.0019113864512182773\n",
            "Epoch 8, Train: 0.0019495016273343936 , Validation: 0.001888360511045903\n",
            "Epoch 9, Train: 0.0019190472059184686 , Validation: 0.0018629565819865094\n",
            "Epoch 10, Train: 0.0018995892964303494 , Validation: 0.0018411521842936053\n",
            "Epoch 11, Train: 0.0018745279230875894 , Validation: 0.0018162628253921866\n",
            "Epoch 12, Train: 0.0018484538639429956 , Validation: 0.0017915634326636791\n",
            "Epoch 13, Train: 0.0018189952994463966 , Validation: 0.0017660065819509328\n",
            "Epoch 14, Train: 0.0017967262528603898 , Validation: 0.0017441597895231098\n",
            "Epoch 15, Train: 0.0017730221947422251 , Validation: 0.0017221492793178185\n",
            "Epoch 16, Train: 0.0017531969817355276 , Validation: 0.0017096241057151928\n",
            "Epoch 17, Train: 0.0017367397668771446 , Validation: 0.0016852354920702055\n",
            "Epoch 18, Train: 0.0017195492658996954 , Validation: 0.0016734032809035853\n",
            "Epoch 19, Train: 0.0017062343726167455 , Validation: 0.0016673491968540474\n",
            "Epoch 20, Train: 0.0016998761896975338 , Validation: 0.0016505551215959713\n",
            "Epoch 21, Train: 0.0016880315169226377 , Validation: 0.001646318501443602\n",
            "Epoch 22, Train: 0.0016777548222336918 , Validation: 0.001633014329476282\n",
            "Epoch 23, Train: 0.00166534611643292 , Validation: 0.0016231011360650883\n",
            "Epoch 24, Train: 0.0016585940721211955 , Validation: 0.0016189417369896547\n",
            "Epoch 25, Train: 0.0016521004844456911 , Validation: 0.0016089855910977348\n",
            "Epoch 26, Train: 0.0016451728391926736 , Validation: 0.0016068598269484938\n",
            "Epoch 27, Train: 0.0016372805895050987 , Validation: 0.0015980438962578773\n",
            "Epoch 28, Train: 0.001635171404434368 , Validation: 0.0015972476133611054\n",
            "Epoch 29, Train: 0.001634650646778755 , Validation: 0.0015919065069174394\n",
            "Epoch 30, Train: 0.0016266825661063193 , Validation: 0.0015884156193351374\n",
            "Epoch 31, Train: 0.0016341051040915772 , Validation: 0.001588727094233036\n",
            "Epoch 32, Train: 0.0016217189313611016 , Validation: 0.0015839454040396958\n",
            "Epoch 33, Train: 0.0016194997397484259 , Validation: 0.001580892246332951\n",
            "Epoch 34, Train: 0.001612052135891281 , Validation: 0.0015784920126898213\n",
            "Epoch 35, Train: 0.0016090662938542664 , Validation: 0.0015741284386022016\n",
            "Epoch 36, Train: 0.0016047578901052476 , Validation: 0.0015730519939679652\n",
            "Epoch 37, Train: 0.0016024671519408002 , Validation: 0.0015703039495274425\n",
            "Epoch 38, Train: 0.0015996387933846564 , Validation: 0.0015699609980219975\n",
            "Epoch 39, Train: 0.0015992220905609428 , Validation: 0.001560592161724344\n",
            "Epoch 40, Train: 0.0015987352864351124 , Validation: 0.0015632020343327895\n",
            "Epoch 41, Train: 0.0016029203045880422 , Validation: 0.0015611493865726517\n",
            "Epoch 42, Train: 0.0015950710121542216 , Validation: 0.001560099417110905\n",
            "Epoch 43, Train: 0.0015923463688232004 , Validation: 0.0015546098144259303\n",
            "Epoch 44, Train: 0.0015950887471670285 , Validation: 0.001555117608862929\n",
            "Epoch 45, Train: 0.0015860191792948172 , Validation: 0.0015522635579109192\n",
            "Epoch 46, Train: 0.001587078428082168 , Validation: 0.0015487015269463882\n",
            "Epoch 47, Train: 0.0015862819180823863 , Validation: 0.00154910817486234\n",
            "Epoch 48, Train: 0.0015841260264627636 , Validation: 0.0015470250841462985\n",
            "Epoch 49, Train: 0.0015855386630399153 , Validation: 0.001545382212731056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Sef3N9Q7E0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "74f62936-9f27-4491-c1f9-5f28e4b11d48"
      },
      "source": [
        "plt.plot(G_losses_train)\r\n",
        "plt.plot(G_losses_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1da04eb208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VANQLD86Q9j9"
      },
      "source": [
        "def test_model():\r\n",
        "\r\n",
        "  Generator.eval()\r\n",
        "\r\n",
        "  for i in range(10):\r\n",
        "    image, augmented_image = valid_set[i]\r\n",
        "    #image = transforms.ToTensor()(image)\r\n",
        "    #image = image.type(torch.FloatTensor)\r\n",
        "    #image = image.unsqueeze(0)\r\n",
        "    #image = image*2.0-1\r\n",
        "\r\n",
        "    #transforms.ToPILImage()((image[0]+1)/2).save(\"real\"+str(i)+\".jpg\")\r\n",
        "    transforms.ToPILImage()(image).save(\"original\"+str(i)+\".jpg\")\r\n",
        "\r\n",
        "    #augmented_image = augment_image(image, i, 1)\r\n",
        "\r\n",
        "    #augmented_image = augmented_image.clamp(0.0, 1.0)\r\n",
        "\r\n",
        "    augmented_image = augmented_image.unsqueeze(0)\r\n",
        "    print(augmented_image.shape)\r\n",
        "\r\n",
        "    transforms.ToPILImage()(augmented_image[0]).save(\"input\"+str(i)+\".jpg\")\r\n",
        "\r\n",
        "    output = Generator(augmented_image.cuda())\r\n",
        "    output = (output+1)/2\r\n",
        "    output = output.clamp(0.0, 1.0)\r\n",
        "    transforms.ToPILImage()(output[0].detach().cpu()).save(\"result\" + str(i) + \".jpg\")\r\n",
        "\r\n",
        "  Generator.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbcSbBVqQ9ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef969b5c-dbe0-48d5-edab-ee6a87c36f6a"
      },
      "source": [
        "test_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n",
            "torch.Size([1, 3, 217, 177])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnjXr_dMQ9dB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}